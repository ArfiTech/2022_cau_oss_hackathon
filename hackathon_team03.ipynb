{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "1AosAX9DXOlc"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArfiTech/2022_cau_oss_hackathon/blob/main/hackathon_team03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AosAX9DXOlc"
      },
      "source": [
        "# **0. 해커톤 진행 주의사항**\n",
        "\n",
        "**1)  개발 관련 주의사항**\n",
        "*   [1. 초기 환경 설정]은 절대 수정하지 말 것\n",
        "*   모든 구현은 [2. 데이터 전처리] 및 [3.모델 생성]에서만 진행\n",
        "*   [4. 모델 저장]에서 team_name 변수 변경 (예.`team_name = 'team01'`)\n",
        " *    트레이닝 중간에 checkpoint를 활용하여 모델을 저장한 경우에도 파일 이름 양식 통일 필수\n",
        "*   Colab 사용중 실수로 데이터 손실이 발생할 수도 있으니 중간 결과값을 github에 업로드 \n",
        " *    \"런타임 -> 런타임 연결 해제 및 삭제\"은 절대 누르지 말 것 (저장한 모델 데이터가 모두 삭제됨)\n",
        " *    \"런타임 -> 런타임 다시시작\"은 클라우드 스토리지에 저장된 모델은 유지됨\n",
        "*   효율적인 구현 및 테스팅을 위해 GPU 가속 기능 활성화\n",
        " *    \"런타임 -> 런타임 유형변경 -> 하드웨어 가속기 -> GPU 설정\"\n",
        "*   주석을 최대한 자세히 작성\n",
        "*   Keras API 관련하여 [Keras Documentation](https://keras.io/) 참조\n",
        "\n",
        "**2) 제출 관련 주의사항**\n",
        "*  제출물\n",
        " *  소스코드 (hackathon_teamXX.ipynb)\n",
        " *  컴파일된 모델 파일 (model_entire_teamXX.h5)\n",
        " *  모델 발표 자료 \n",
        "* 제출 기한: **오후 6시 (단, 발표자료는 12시)**\n",
        "* 제출 방법: [GitHub README](https://github.com/cauosshackathonta/2022_cau_oss_hackathon/) 참조\n",
        "\n",
        " \n",
        "**3) 평가 관련 주의사항**\n",
        "*  모델 성능 = 테스트 데이터 셋 분류 정확도\n",
        " *  model.evaluate(x_test, y_test)\n",
        "*  제출된 모델들의 테스트 데이터 셋 분류 정확도를 기준으로 수상작 결정\n",
        "*  수상 후보들에 대해서는 소스코드를 기반으로 모델 재검증 \n",
        " \n",
        "**4) 수상 실격 사유**\n",
        "*  유사한 소스코드가 적발될 경우\n",
        "*  Pre-trained 모델을 사용한 경우 (transfer learning 포함)\n",
        "*  소스코드와 제출된 모델이 상이한 경우\n",
        "*  개발 관련 주의사항을 지키지 않은 경우\n",
        " *  예: [초기 환경 설정]을 수정한 경우\n",
        "*  데이터 셋을 변조한 경우\n",
        " *  예. 테스트 데이터 셋을 트레이닝 데이터 셋에 포함하여 모델 생성 \n",
        "*  주석이 소스코드와 맞지 않거나 미비할 경우\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67lwEXhUqys1"
      },
      "source": [
        "# **1. 초기 환경 설정**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ms5PBBJ1qSC6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "775e841c-0594-482c-9eff-15779385b6e9"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals, unicode_literals\n",
        "\n",
        "# tensorflow와 tf.keras 및 관련 라이브러리 임포트\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras.utils import np_utils\n",
        "from keras import datasets, layers, models\n",
        "\n",
        "# 데이터셋 로드 (MNIST, fashion-MNIST, Kujushiji-MNIST, MNIST_corrupted (test only))\n",
        "train_ds, test_ds = tfds.load('mnist', split=['train', 'test'], shuffle_files=False, batch_size=-1)\n",
        "\n",
        "train_ds2, test_ds2 = tfds.load('fashion_mnist', split=['train', 'test'], shuffle_files=False, batch_size=-1)\n",
        "train_ds2['label'] += 10;\n",
        "test_ds2['label'] += 10;\n",
        "\n",
        "train_ds3, test_ds3 = tfds.load('kmnist', split=['train', 'test'], shuffle_files=False, batch_size=-1)\n",
        "train_ds3['label'] += 20;\n",
        "test_ds3['label'] += 20;\n",
        "\n",
        "test_ds4 = tfds.load('mnist_corrupted/zigzag', split='test', shuffle_files=False, batch_size=-1)\n",
        "\n",
        "# 데이터셋 병합 (training: 180,000개, test: 40,000개)\n",
        "x_train = np.append(np.append(train_ds['image'], train_ds2['image'], 0), train_ds3['image'], 0);\n",
        "y_train = np.append(np.append(train_ds['label'], train_ds2['label'], 0), train_ds3['label'], 0);\n",
        "\n",
        "x_test = np.append(np.append(np.append(test_ds['image'], test_ds2['image'], 0), test_ds3['image'], 0), test_ds4['image'], 0);\n",
        "y_test = np.append(np.append(np.append(test_ds['label'], test_ds2['label'], 0), test_ds3['label'], 0), test_ds4['label'], 0);\n",
        "\n",
        "# 분류를 위해 클래스 벡터를 바이너리 매트릭스로 변환\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "\n",
        "# 총 클래스 개수: 30, 입력 데이터 구조: (28, 28, 1)\n",
        "num_classes = y_train.shape[1]\n",
        "input_shape = x_train.shape[1:]\n",
        "print(num_classes, input_shape)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30 (28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-YjppJpXBO9"
      },
      "source": [
        "# **2. 데이터 전처리**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZ9KWTBP6AI1"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "from numpy import expand_dims\n",
        "# 데이터 전처리 (예: normalization)\n",
        "# 원본 데이터와 전처리 후 데이터를 구분하기 위해, 변수명 x_train_after, x_test_after를 변경하지 말 것\n",
        "x_train_after = x_train / 255\n",
        "x_test_after = x_test / 255"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-lo-O1yiFpY"
      },
      "source": [
        "# **3. 모델 생성**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZP4eRmRqgRp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1736a7ad-3f8d-40c9-ea5b-7f114bf05388"
      },
      "source": [
        "# 순차 모델 생성 (가장 기본구조)\n",
        "model = keras.Sequential()\n",
        "\n",
        "# 1st Convolution layer\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=keras.regularizers.l2(0.01)))\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=keras.regularizers.l2(0.01)))\n",
        "model.add(keras.layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# 2nd Convolution layer\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=keras.regularizers.l2(0.01)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=keras.regularizers.l2(0.01)))\n",
        "model.add(keras.layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# 3rd Convolution layer\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=keras.regularizers.l2(0.01)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=keras.regularizers.l2(0.01)))\n",
        "model.add(keras.layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Dropout and flatten\n",
        "model.add(keras.layers.Dropout(0.25))\n",
        "model.add(keras.layers.Flatten())\n",
        "\n",
        "# Output layer: fully-connected layer and Dropout\n",
        "model.add(keras.layers.Dense(1024, activation='relu'))\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "model.add(keras.layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# 모델 컴파일\n",
        "# optimizer: 모델을 업데이트 하는 방식\n",
        "# loss: 모델의 정확도를 판단하는 방식\n",
        "# metrics: 트레이닝 및 테스팅 성능 모니터링을 위한 평가지표\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "#adam\n",
        "#adamax\n",
        "#nadam\n",
        "\n",
        "\n",
        "# 체크포인트 생성\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath='/content/checkpoint_entire_best.h5', monitor='val_accuracy', verbose=1, save_weight_only=False, save_best_only=True, mode='auto')\n",
        "\n",
        "# 모델 트레이닝\n",
        "# batch_size: 전체 데이터셋 중 몇개씩 학습시킬 것인지\n",
        "# epoch: 학습에 전체 데이터셋이 총 몇번 이용될 것인지\n",
        "# shuffle: 학습전에 트레이닝 데이터셋을 랜덤하게 섞을 것인지\n",
        "# validation_data: 중간 성능 검증에 사용할 data set (x_test1_after, x_test2_after, 혹은 둘을 merge해서 사용)\n",
        "model.fit(x_train_after, y_train, batch_size = 128, epochs = 30, shuffle=True, callbacks=[cp_callback], validation_data=(x_test_after, y_test))\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1406/1407 [============================>.] - ETA: 0s - loss: 1.3675 - accuracy: 0.8602\n",
            "Epoch 1: val_accuracy improved from -inf to 0.86785, saving model to /content/checkpoint_entire_best.h5\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 1.3674 - accuracy: 0.8602 - val_loss: 0.6001 - val_accuracy: 0.8679\n",
            "Epoch 2/30\n",
            "1405/1407 [============================>.] - ETA: 0s - loss: 0.4316 - accuracy: 0.9120\n",
            "Epoch 2: val_accuracy improved from 0.86785 to 0.87545, saving model to /content/checkpoint_entire_best.h5\n",
            "1407/1407 [==============================] - 19s 13ms/step - loss: 0.4316 - accuracy: 0.9120 - val_loss: 0.5564 - val_accuracy: 0.8755\n",
            "Epoch 3/30\n",
            "1405/1407 [============================>.] - ETA: 0s - loss: 0.3754 - accuracy: 0.9203\n",
            "Epoch 3: val_accuracy improved from 0.87545 to 0.88673, saving model to /content/checkpoint_entire_best.h5\n",
            "1407/1407 [==============================] - 19s 13ms/step - loss: 0.3753 - accuracy: 0.9203 - val_loss: 0.4821 - val_accuracy: 0.8867\n",
            "Epoch 4/30\n",
            "1403/1407 [============================>.] - ETA: 0s - loss: 0.3459 - accuracy: 0.9258\n",
            "Epoch 4: val_accuracy did not improve from 0.88673\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.3459 - accuracy: 0.9258 - val_loss: 0.5206 - val_accuracy: 0.8825\n",
            "Epoch 5/30\n",
            "1403/1407 [============================>.] - ETA: 0s - loss: 0.3251 - accuracy: 0.9296\n",
            "Epoch 5: val_accuracy improved from 0.88673 to 0.90265, saving model to /content/checkpoint_entire_best.h5\n",
            "1407/1407 [==============================] - 19s 13ms/step - loss: 0.3251 - accuracy: 0.9296 - val_loss: 0.4134 - val_accuracy: 0.9026\n",
            "Epoch 6/30\n",
            "1407/1407 [==============================] - ETA: 0s - loss: 0.3101 - accuracy: 0.9319\n",
            "Epoch 6: val_accuracy did not improve from 0.90265\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 0.3101 - accuracy: 0.9319 - val_loss: 0.4276 - val_accuracy: 0.8970\n",
            "Epoch 7/30\n",
            "1404/1407 [============================>.] - ETA: 0s - loss: 0.2989 - accuracy: 0.9339\n",
            "Epoch 7: val_accuracy did not improve from 0.90265\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 0.2988 - accuracy: 0.9340 - val_loss: 0.4778 - val_accuracy: 0.8874\n",
            "Epoch 8/30\n",
            "1404/1407 [============================>.] - ETA: 0s - loss: 0.2897 - accuracy: 0.9357\n",
            "Epoch 8: val_accuracy improved from 0.90265 to 0.90602, saving model to /content/checkpoint_entire_best.h5\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.2898 - accuracy: 0.9357 - val_loss: 0.3983 - val_accuracy: 0.9060\n",
            "Epoch 9/30\n",
            "1404/1407 [============================>.] - ETA: 0s - loss: 0.2815 - accuracy: 0.9373\n",
            "Epoch 9: val_accuracy did not improve from 0.90602\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 0.2814 - accuracy: 0.9374 - val_loss: 0.4411 - val_accuracy: 0.9002\n",
            "Epoch 10/30\n",
            "1403/1407 [============================>.] - ETA: 0s - loss: 0.2729 - accuracy: 0.9390\n",
            "Epoch 10: val_accuracy improved from 0.90602 to 0.90670, saving model to /content/checkpoint_entire_best.h5\n",
            "1407/1407 [==============================] - 19s 14ms/step - loss: 0.2729 - accuracy: 0.9390 - val_loss: 0.3830 - val_accuracy: 0.9067\n",
            "Epoch 11/30\n",
            "1406/1407 [============================>.] - ETA: 0s - loss: 0.2668 - accuracy: 0.9394\n",
            "Epoch 11: val_accuracy did not improve from 0.90670\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 0.2668 - accuracy: 0.9394 - val_loss: 0.3976 - val_accuracy: 0.9025\n",
            "Epoch 12/30\n",
            "1406/1407 [============================>.] - ETA: 0s - loss: 0.2611 - accuracy: 0.9409\n",
            "Epoch 12: val_accuracy improved from 0.90670 to 0.90770, saving model to /content/checkpoint_entire_best.h5\n",
            "1407/1407 [==============================] - 19s 14ms/step - loss: 0.2611 - accuracy: 0.9409 - val_loss: 0.3878 - val_accuracy: 0.9077\n",
            "Epoch 13/30\n",
            "1405/1407 [============================>.] - ETA: 0s - loss: 0.2578 - accuracy: 0.9419\n",
            "Epoch 13: val_accuracy did not improve from 0.90770\n",
            "1407/1407 [==============================] - 19s 13ms/step - loss: 0.2578 - accuracy: 0.9419 - val_loss: 0.4102 - val_accuracy: 0.9033\n",
            "Epoch 14/30\n",
            "1406/1407 [============================>.] - ETA: 0s - loss: 0.2545 - accuracy: 0.9424\n",
            "Epoch 14: val_accuracy did not improve from 0.90770\n",
            "1407/1407 [==============================] - 19s 14ms/step - loss: 0.2545 - accuracy: 0.9424 - val_loss: 0.3849 - val_accuracy: 0.9050\n",
            "Epoch 15/30\n",
            "1407/1407 [==============================] - ETA: 0s - loss: 0.2505 - accuracy: 0.9434\n",
            "Epoch 15: val_accuracy improved from 0.90770 to 0.90873, saving model to /content/checkpoint_entire_best.h5\n",
            "1407/1407 [==============================] - 19s 14ms/step - loss: 0.2505 - accuracy: 0.9434 - val_loss: 0.3728 - val_accuracy: 0.9087\n",
            "Epoch 16/30\n",
            "1406/1407 [============================>.] - ETA: 0s - loss: 0.2481 - accuracy: 0.9439\n",
            "Epoch 16: val_accuracy did not improve from 0.90873\n",
            "1407/1407 [==============================] - 19s 14ms/step - loss: 0.2481 - accuracy: 0.9439 - val_loss: 0.3992 - val_accuracy: 0.9044\n",
            "Epoch 17/30\n",
            "1407/1407 [==============================] - ETA: 0s - loss: 0.2456 - accuracy: 0.9442\n",
            "Epoch 17: val_accuracy improved from 0.90873 to 0.90968, saving model to /content/checkpoint_entire_best.h5\n",
            "1407/1407 [==============================] - 19s 13ms/step - loss: 0.2456 - accuracy: 0.9442 - val_loss: 0.3766 - val_accuracy: 0.9097\n",
            "Epoch 18/30\n",
            "1403/1407 [============================>.] - ETA: 0s - loss: 0.2426 - accuracy: 0.9447\n",
            "Epoch 18: val_accuracy did not improve from 0.90968\n",
            "1407/1407 [==============================] - 19s 13ms/step - loss: 0.2426 - accuracy: 0.9447 - val_loss: 0.3926 - val_accuracy: 0.9040\n",
            "Epoch 19/30\n",
            "1405/1407 [============================>.] - ETA: 0s - loss: 0.2411 - accuracy: 0.9456\n",
            "Epoch 19: val_accuracy did not improve from 0.90968\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 0.2410 - accuracy: 0.9456 - val_loss: 0.4208 - val_accuracy: 0.9042\n",
            "Epoch 20/30\n",
            "1404/1407 [============================>.] - ETA: 0s - loss: 0.2380 - accuracy: 0.9458\n",
            "Epoch 20: val_accuracy did not improve from 0.90968\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 0.2379 - accuracy: 0.9459 - val_loss: 0.4109 - val_accuracy: 0.8971\n",
            "Epoch 21/30\n",
            "1404/1407 [============================>.] - ETA: 0s - loss: 0.2367 - accuracy: 0.9465\n",
            "Epoch 21: val_accuracy did not improve from 0.90968\n",
            "1407/1407 [==============================] - 19s 14ms/step - loss: 0.2369 - accuracy: 0.9465 - val_loss: 0.3992 - val_accuracy: 0.9043\n",
            "Epoch 22/30\n",
            "1406/1407 [============================>.] - ETA: 0s - loss: 0.2354 - accuracy: 0.9463\n",
            "Epoch 22: val_accuracy did not improve from 0.90968\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 0.2354 - accuracy: 0.9463 - val_loss: 0.4047 - val_accuracy: 0.9031\n",
            "Epoch 23/30\n",
            "1406/1407 [============================>.] - ETA: 0s - loss: 0.2306 - accuracy: 0.9480\n",
            "Epoch 23: val_accuracy did not improve from 0.90968\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 0.2306 - accuracy: 0.9480 - val_loss: 0.4271 - val_accuracy: 0.9056\n",
            "Epoch 24/30\n",
            "1406/1407 [============================>.] - ETA: 0s - loss: 0.2306 - accuracy: 0.9476\n",
            "Epoch 24: val_accuracy did not improve from 0.90968\n",
            "1407/1407 [==============================] - 19s 13ms/step - loss: 0.2306 - accuracy: 0.9476 - val_loss: 0.4611 - val_accuracy: 0.8963\n",
            "Epoch 25/30\n",
            "1406/1407 [============================>.] - ETA: 0s - loss: 0.2285 - accuracy: 0.9480\n",
            "Epoch 25: val_accuracy did not improve from 0.90968\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 0.2284 - accuracy: 0.9480 - val_loss: 0.4164 - val_accuracy: 0.9097\n",
            "Epoch 26/30\n",
            "1406/1407 [============================>.] - ETA: 0s - loss: 0.2282 - accuracy: 0.9479\n",
            "Epoch 26: val_accuracy did not improve from 0.90968\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 0.2282 - accuracy: 0.9479 - val_loss: 0.5006 - val_accuracy: 0.8930\n",
            "Epoch 27/30\n",
            "1405/1407 [============================>.] - ETA: 0s - loss: 0.2269 - accuracy: 0.9480\n",
            "Epoch 27: val_accuracy did not improve from 0.90968\n",
            "1407/1407 [==============================] - 19s 14ms/step - loss: 0.2269 - accuracy: 0.9480 - val_loss: 0.4039 - val_accuracy: 0.9063\n",
            "Epoch 28/30\n",
            "1405/1407 [============================>.] - ETA: 0s - loss: 0.2251 - accuracy: 0.9487\n",
            "Epoch 28: val_accuracy did not improve from 0.90968\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 0.2251 - accuracy: 0.9487 - val_loss: 0.4340 - val_accuracy: 0.9021\n",
            "Epoch 29/30\n",
            "1405/1407 [============================>.] - ETA: 0s - loss: 0.2231 - accuracy: 0.9492\n",
            "Epoch 29: val_accuracy did not improve from 0.90968\n",
            "1407/1407 [==============================] - 19s 13ms/step - loss: 0.2231 - accuracy: 0.9492 - val_loss: 0.4051 - val_accuracy: 0.9060\n",
            "Epoch 30/30\n",
            "1403/1407 [============================>.] - ETA: 0s - loss: 0.2211 - accuracy: 0.9496\n",
            "Epoch 30: val_accuracy improved from 0.90968 to 0.91217, saving model to /content/checkpoint_entire_best.h5\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.2211 - accuracy: 0.9496 - val_loss: 0.3668 - val_accuracy: 0.9122\n",
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_82 (Conv2D)          (None, 28, 28, 32)        320       \n",
            "                                                                 \n",
            " conv2d_83 (Conv2D)          (None, 28, 28, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_50 (MaxPoolin  (None, 14, 14, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_84 (Conv2D)          (None, 14, 14, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_85 (Conv2D)          (None, 14, 14, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_51 (MaxPoolin  (None, 7, 7, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_86 (Conv2D)          (None, 7, 7, 128)         73856     \n",
            "                                                                 \n",
            " conv2d_87 (Conv2D)          (None, 7, 7, 128)         147584    \n",
            "                                                                 \n",
            " max_pooling2d_52 (MaxPoolin  (None, 3, 3, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_24 (Dropout)        (None, 3, 3, 128)         0         \n",
            "                                                                 \n",
            " flatten_13 (Flatten)        (None, 1152)              0         \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 1024)              1180672   \n",
            "                                                                 \n",
            " dropout_25 (Dropout)        (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_36 (Dense)            (None, 30)                30750     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,497,854\n",
            "Trainable params: 1,497,854\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CKztKsFQjMfR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QR9WUYXxqtfR"
      },
      "source": [
        "# **4. 모델 저장**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wi9yznz4qvzK"
      },
      "source": [
        "save_path = '/content/'\n",
        "team_name = 'team03'\n",
        "\n",
        "# 트레이닝된 전체 모델을 저장합니다.\n",
        "model.save(save_path +  'model_entire_'+ team_name + '.h5')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aPbgI-c-Kj8"
      },
      "source": [
        "# **5. 모델 로드 및 평가**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7WONVxH-Kt6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a6557c8-c79b-411d-b541-16ff9edfe413"
      },
      "source": [
        "save_path = '/content/'\n",
        "team_name = 'team03'\n",
        "\n",
        "model = keras.models.load_model(save_path + 'model_entire_' + team_name + '.h5')\n",
        "\n",
        "model.evaluate(x_test_after, y_test)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.3668 - accuracy: 0.9122\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3667975664138794, 0.9121749997138977]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    }
  ]
}